{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - MNIST Beispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Trainingsdaten: (60000, 28, 28)\n",
      "Dimension Bild Nr. 5: (28, 28)\n",
      "Label zu Bild Nr. 5: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "test_labels_ori = test_labels\n",
    "\n",
    "print(\"Shape Trainingsdaten: {}\".format(train_images.shape))\n",
    "print(\"Dimension Bild Nr. 5: {}\".format(train_images[5].shape))\n",
    "print(\"Label zu Bild Nr. 5: {}\".format(train_labels[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdatensatz:(60000, 28, 28, 1)\n",
      "Testdatensatz:(10000, 28, 28, 1)\n",
      "Wir haben 60000 Trainingsbilder und 10000 Testbilder.\n"
     ]
    }
   ],
   "source": [
    "NrTrainimages = train_images.shape[0]\n",
    "NrTestimages = test_images.shape[0]\n",
    "\n",
    "print(\"Trainingsdatensatz:{}\".format(train_images.shape))\n",
    "print(\"Testdatensatz:{}\".format(test_images.shape))\n",
    "\n",
    "print(\"Wir haben {} Trainingsbilder und {} Testbilder.\".format(NrTrainimages, NrTestimages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "randindex = random.randint(0,60000)\n",
    "plttitle = \"Trainingsbild Nr. {} \\n Klasse: {}\".format(randindex,train_labels[randindex])\n",
    "plt.imshow(train_images[randindex].reshape(28,28), cmap='gray')\n",
    "plt.title(plttitle)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_inputshape = train_images[0].shape\n",
    "mnist_inputshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = r\"D:/logs\"\n",
    "LOGDIR = os.path.join(basedir,\"tb_logs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensorboard = TensorBoard(log_dir = LOGDIR,\n",
    "                             histogram_freq=0,\n",
    "                            write_graph=True,\n",
    "                            write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 192,202\n",
      "Trainable params: 192,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5), \n",
    "                activation = 'relu',\n",
    "                input_shape=mnist_inputshape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5,5),activation= 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_batch_size = 128\n",
    "my_num_classes = 10\n",
    "my_epochs = 12\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='Adam',\n",
    "             metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.3730 - acc: 0.8801 - val_loss: 0.0554 - val_acc: 0.9831\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.1082 - acc: 0.9675 - val_loss: 0.0363 - val_acc: 0.9888\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 98s 2ms/step - loss: 0.0796 - acc: 0.9767 - val_loss: 0.0316 - val_acc: 0.9904\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 97s 2ms/step - loss: 0.0667 - acc: 0.9804 - val_loss: 0.0280 - val_acc: 0.9916\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0620 - acc: 0.9820 - val_loss: 0.0289 - val_acc: 0.9903\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0536 - acc: 0.9839 - val_loss: 0.0226 - val_acc: 0.9925\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0490 - acc: 0.9855 - val_loss: 0.0194 - val_acc: 0.9939\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0444 - acc: 0.9867 - val_loss: 0.0202 - val_acc: 0.9939\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0433 - acc: 0.9868 - val_loss: 0.0201 - val_acc: 0.9935\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.0406 - acc: 0.9882 - val_loss: 0.0207 - val_acc: 0.9931\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0379 - acc: 0.9882 - val_loss: 0.0241 - val_acc: 0.9926\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0207 - val_acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,train_labels,\n",
    "         batch_size=my_batch_size,\n",
    "         callbacks=[my_tensorboard],\n",
    "         epochs=my_epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(test_images,test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1510e860>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 650us/step\n",
      "Test Verlust: 0.0206829725912\n",
      "Test Genauigkeit: 0.994\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels)\n",
    "print('Test Verlust:', score[0])\n",
    "print('Test Genauigkeit:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
